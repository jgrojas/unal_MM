---
title: "prueba de hip√≥tesis en R"
author: "JRojas, MRamirez, LRomero,ADarghan"
date: "6/24/2020"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '1'
    toc_float: yes
  bookdown::html_document2:
    number_sections: no
    toc: yes
    toc_depth: 1
    toc_float: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducci√≥n

A continuaci√≥n se presentan una serie de ejercicios que permitiran interiorizar los conocimientos aprendidos en relaci√≥n a pruebas de hip√≥tesis desde R. El documento contiene la soluci√≥n de 6 ejercicios que hacen √©nfasis en:

* Prueba t - Una muestra
* Prueba t - Dos muestras independientes
* Prueba t - Dos muestras dependientes
* Funci√≥n distribuci√≥n uniforme
* Prueba F para el cociente de dos varianzas
* Prueba T$^2$ de Hotelling para dos muestras independientes

El desarrollo del taller hace parte del contenido acad√©mico elaborado por el profesor Aquiles Enrique Darghan Contreras para la materia de de M√©todos Multivariados.

Previo a la soluci√≥n de los ejercicios es necesario instalar y cargar las siguientes librer√≠as.

```{r message=FALSE, include=TRUE}
library("kableExtra")
```

# Prueba t-Una muestra.  

Una l√≠nea base de longitud calibrada en 955m se midi√≥ 10 veces. Cada medida es independiente y se hizo con la misma precisi√≥n.

Los datos de las mediciones son:
```{r echo=FALSE}

med=c(965.1,955.1,954.8,956.2,956.4,957.2,958.1,960.4,953.2,954.8)
table=data.frame(M1=numeric(),M2=numeric(),M3=numeric(),M4=numeric(),M5=numeric(),M6=numeric(),M7=numeric(),M8=numeric(),M9=numeric(),M10=numeric())
table[1,]=0
table$M1[0]=med[1];table$M2=med[2];table$M3=med[3];table$M4=med[4];table$M5=med[5];table$M6=med[6];table$M7=med[7];table$M8=med[8];table$M9=med[9];table$M10=med[10]

kable(table) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

a) Pruebe utilizando un nivel de confianza del 10% si la distancia medida es estad√≠sticamente diferente de la calibrada.

```{r}
med=c(965.1,955.1,954.8,956.2,956.4,957.2,958.1,960.4,953.2,954.8)
pruebat <- t.test(med,alternative = "t",mu = 0,var.equal = F, conf.level = 0.90);
pruebat #La media  est√° en la cola inferior
```

b) Remuestree el vector de mediciones y obtenga el error est√°ndar Bootstrap y util√≠celo en la prueba t-Student y compare con el resultado anterior( Explique). (Realice 100 simulaciones)

```{r}
set.seed(2020)
B = 100 #repeticiones Bootstrap 
df=data.frame(med)
remuestreo <- with(df,matrix(sample(med,size = 10,replace = TRUE), B, 10))
dim(remuestreo)
####### las medias de las submuestras
medias <- apply(remuestreo, 1, mean)
pruebat <- t.test(medias,alternative = "t",mu = 955,var.equal = F, conf.level = 0.90);
pruebat 
```

Conclusi√≥n: Los resultados consideran que la media no es 955 sino que est√° dentro en el rango 959.3-960.5

c) ¬øCu√°nto deber√≠a ser n en la expresi√≥n de la prueba t para que el error est√°ndar Bootstrap sea el mismo que el asumido en la prueba?

Si los datos son mediciones, la primera prueba no tendr√≠a sentido porque solo es una media. En este caso la primera prueba estar√≠a asumiendo que cada medici√≥n es una valor promedio diferente y no una medici√≥n. Para que el error est√°ndar Bootstrap tenga sentido deber√≠amos tener m√°s repeticiones y valores promedios de diferentes conjuntos de datos.







# Prueba T$^2$ Una muestra. 

Se est·n probando dos dispositivos que permiten medir el ·ngulo recto y la distancia a una serie de puntos en un transecto. La figura muestra la situaciÛn:


Por lo anterior se procede a cargar los datos que se encuentran en la tabla mostrada, haciendo acotaciÛn de que los valores angulares deben ser convertidos a valores decimales:

```{r}
distancia=c(100.02,200.12,300.08,399.96,419.94,519.99,620.04,720.08,100.06,199.45,298.08,398.96,420.15,520.02,621.01,721.11)
angulo=c(90.004444444, 90.002222222, 89.996666667, 90.017222222, 89.996666667, 90.005555556, 89.993333333, 90.001666667, 90.035833333, 90.021111111, 90.988333333, 89.017222222, 89.835555556, 89.038888889, 89.165555556, 89.029444444)
disp <- gl(2, 8, 16, labels = c("A", "B"))
datos5=data.frame(distancia,angulo,disp)
datos5a=datos5[1:8,]
datos5b=datos5[9:16,]
```


a. Realice la prueba t-Student de forma convencional para dos muestras independientes y saque las conclusiones por separado de la comparaciÛn de las medias de longitud y ·ngulos para ambos dispositivos (sea cuidadoso al momento de obtener varianzas en ·ngulos). Utilice un nivel de confianza del 95% en cada caso.

```{r}
pda1=t.test(datos5a$distancia,datos5b$distancia, alternative = "two.sided", var.equal = T, mu=0, conf.level = 0.95)
pda1
pda2=t.test(datos5a$angulo,datos5b$angulo, alternative = "two.sided", var.equal = T, mu=0, conf.level = 0.95)
pda2

```

Para los dos casos no se puede rechazar la hipotesis nula de igualdad de medias, es decir que las medias de los dos grupos pueden asumirse como iguales.

b. Compare los resultados anteriores con el resultado actualizado si utilizara la correcciÛn de Bonferroni.

```{r}
pajust <- function(hipotesis,alfa){
  pvalor = 1-((1-alfa)^(1/hipotesis))
  return(pvalor)
}
crrb=pajust(2, 0.05) ## C·lculo del nuevo nivel de significancia por Bonferroni
crrb
crrb=1-crrb ## Nivel de Confianza con Bonferroni
crrb
```

A pesar de que es m·s exigente por correcciÛn de Bonferroni (nivel de confianza de 97.5%), a˙n no se puede rechzar las hÌpotesis nulas debido a que los p-valor de las pruebas son mayores a 0.10, es decir mucho m·s que el nivel de significancia.

c. Obtenga el coeficiente de correlaciÛn para este tipo de datos (Pearson) sin discriminar por dispositivo.

```{r}
cor(datos5$distancia,datos5$angulo)
```

Seg˙n el Ìndice de correlaciÛn 

d. Estime el error est·ndar para la diferencia de medias  por mÈtodo Bootstrap para ajustar la prueba t con este error y compare con el resultado sin el mÈtodo Bootstrap.

```{r}
n.datos <- with(datos5, summary(disp)) #cada tamano de muestra
B = 1000 #repeticiones Bootstrap 
#las submuestras de cada metodo
met.a.dist <- with(datos5a,
              matrix(sample(datos5a$distancia,
                            size = n.datos[1]*B,
                            replace = TRUE), B, n.datos[1]))
met.a.ang <- with(datos5a,
                   matrix(sample(datos5a$angulo,
                                 size = n.datos[1]*B,
                                 replace = TRUE), B, n.datos[1]))
met.b.dist <- with(datos5b,
              matrix(sample(datos5b$distancia,
                            size = n.datos[1]*B,
                            replace = TRUE), B, n.datos[2]))
met.b.ang <- with(datos5b,
                  matrix(sample(datos5b$angulo,
                                size = n.datos[1]*B,
                                replace = TRUE), B, n.datos[2]))

medias.a.dist<- apply(met.a.dist, 1, mean)
medias.a.ang<- apply(met.a.ang, 1, mean)
medias.b.dist <- apply(met.b.dist, 1, mean)
medias.b.ang<- apply(met.b.ang, 1, mean)

pdistd<-t.test(medias.a.dist,medias.b.dist,alternative = "two.sided",0, conf.level = 0.95, var.equal = F) ## Se rechaza Ho
pdang<-t.test(medias.a.ang,medias.b.ang,alternative = "two.sided", mu=0, conf.level = 0.95)  ## No se puede rechazar Ho -- mientras que en el est·ndar si se rechazo
pdang$p.value

eebdm <- sd(medias.a.dist-medias.b.dist) 
eecdist <- c((mean(medias.a.dist)-mean(medias.b.dist))/pdistd$statistic);eecdist
eebdma <- sd(medias.a.ang-medias.b.ang) 
eecang <- c((mean(medias.a.ang)-mean(medias.b.ang))/pdang$statistic);eecang
########## calculando el estadastico t bootstrap
tbootdist <- abs((mean(medias.a.dist)-mean(medias.b.dist))/eebdm)
pvalor_bootdist <- pt(tboot,n.datos[1]+n.datos[2]-2,lower.tail = F)
tbootang <- abs((mean(medias.a.ang)-mean(medias.b.ang))/eebdma)
pvalor_bootangt <- pt(tbootang,n.datos[1]+n.datos[2]-2,lower.tail = F)

```

e. Use el resultado anterior y ajuste adem·s con la correcciÛn de Bonferroni.

```{r}

## E


## Con Bonferroni a una confianza de 97.5% a cada uno por separado, no se puede rechazar la Ho de distancia igual que el ·ngulo
```


f. Aplique la prueba T2 de Hotelling para comparar el vector de medias bivariado asumiendo varianzas iguales y un nivel de confianza del 95%.
	
	
Ho:[???(??_(d-A)@??_(a-A) )]=[???(??_(d-B)@??_(a-B) )]

```{r}
Z=as.matrix(datos5[,1:2])
g=as.matrix(datos5[,3])

PruebaH2 <- HotellingsT2(Z~g, mu = c(0,0)) ##
```


g. Utilice la prueba M de Box de Biotools y verifique si ambas matrices de varianzas y covarianzas son estadÌsticamente iguales al 95%. (cuide el c·lculo de las varianzas en datos angulares). De ser diferentes las varianzas consulte el texto de Wichern para que utilice la prueba de Hotelling para varianzas y covarianzas desiguales y con la ayuda de alguna funciÛn en R/Python contraste las hipÛtesis bivariadas de longitud y ·ngulo nuevamente.

```{r}
## g

library(biotools)
## Matriz de varianzas y covarianzas metodo A
data.a <- as.matrix((filter(datos5[, 1:2], disp == "A")), ncol = 2)
sa <- var(data.a)
## Matriz de varianzas y covarianzas metodo B
data.b <- as.matrix((filter(datos5[, 1:2], disp == "B")), ncol = 2)
sb <- var(data.b)
## Prueba M de Box
boxM(dft2i[,-3],dft2i[,3])

require(ergm)

approx.hotelling.diff.test(datos5a[,-3], datos5b[,-3], mu0 = 0, assume.indep = T, var.equal = T)

require(rrcov)

T2.test(datos5a[,-3],
        datos5b[,-3], method = "c")
```


h. Realice alg˙n gr·fico radial o de datos circulares para visualizar el comportamiento de los ·ngulos y simult·neamente visualice las distancias.

```{r}
# h

ggplot(df, aes(x=distancia, y=angulo, col=dispositivo, group=dispositivo)) + geom_point() + coord_polar()

```

i. Si ambos dispositivos se comportan igual para ambas medidas (es decir no se rechazÛ Ho bivariada, utilice el an·lisis de regresiÛn lineal para ajustar un modelo para estimar la distancia a partir del ·ngulo. øVale la pena este ajuste? Ajuste el mismo modelo con el inverso de la distancia y compare resultados. øComo a mayor distancia la medida de longitud se puede tornar m·s imprecisa, valdrÌa ponderar el ·ngulo por el inverso de la distancia para obtener el ·ngulo promedio de todas las medidas? Realice el c·lculo ponderado y compare con la media aritmÈtica usual del ·ngulo. Explique estos resultados.

```{r}
# i

model1=lm(datos5$distancia ~ datos5$angulo)
summary(model1) 

model2=lm(1/datos5$distancia ~ datos5$angulo)
summary(model2)

datos5a$inversdis=1/datos5a$distancia
datos5a$angulopond=datos5a$inversdis*datos5a$angulo
datos5b$inversdis=1/datos5b$distancia
datos5b$angulopond=datos5b$inversdis*datos5b$angulo
cor(datos5b$angulopond,datos5a$angulopond)
mean(datos5a$angulopond)
mean(datos5a$angulopond)
```




---
title: "Pruebas de hipótesis en R"
author: "JRojas, MRamirez, LRomero,ADarghan"
date: "6/24/2020"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '1'
    toc_float: yes
  bookdown::html_document2:
    number_sections: no
    toc: yes
    toc_depth: 1
    toc_float: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

A continuación se presentan una serie de ejercicios que permitiran interiorizar los conocimientos aprendidos en relación a pruebas de hipótesis desde R. El documento contiene la solución de 6 ejercicios que hacen énfasis en:

* Prueba t - Una muestra
* Prueba t - Dos muestras independientes
* Prueba t - Dos muestras dependientes
* Función distribución uniforme
* Prueba F para el cociente de dos varianzas
* Prueba T$^2$ de Hotelling para dos muestras independientes

El desarrollo del taller hace parte del contenido académico elaborado por el profesor Aquiles Enrique Darghan Contreras para la materia de de Métodos Multivariados.

Previo a la solución de los ejercicios es necesario instalar y cargar las siguientes librerías y funciones diseñadas para el análisis.

```{r message=FALSE, include=TRUE}
library(dplyr)
library(kableExtra)
library(ggplot2)
```

```{r message=FALSE}
pajust <- function(hipotesis,alfa){
  pvalor = 1-((1-alfa)^(1/hipotesis))
  return(pvalor)
}
```

# Prueba t-Una muestra.  

Una línea base de longitud calibrada en 955m se midió 10 veces. Cada medida es independiente y se hizo con la misma precisión.

Los datos de las mediciones son:
```{r echo=FALSE}

med=c(965.1,955.1,954.8,956.2,956.4,957.2,958.1,960.4,953.2,954.8)
table=data.frame(M1=numeric(),M2=numeric(),M3=numeric(),M4=numeric(),M5=numeric(),M6=numeric(),M7=numeric(),M8=numeric(),M9=numeric(),M10=numeric())
table[1,]=0
table$M1[0]=med[1];table$M2=med[2];table$M3=med[3];table$M4=med[4];table$M5=med[5];table$M6=med[6];table$M7=med[7];table$M8=med[8];table$M9=med[9];table$M10=med[10]

kable(table) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

a) Pruebe utilizando un nivel de confianza del 10% si la distancia medida es estadísticamente diferente de la calibrada.

```{r}
med=c(965.1,955.1,954.8,956.2,956.4,957.2,958.1,960.4,953.2,954.8)
pruebat <- t.test(med,alternative = "t",mu = 0,var.equal = F, conf.level = 0.90);
pruebat #La media  está en la cola inferior
```

b) Remuestree el vector de mediciones y obtenga el error estándar Bootstrap y utilícelo en la prueba t-Student y compare con el resultado anterior( Explique). (Realice 100 simulaciones)

```{r}
set.seed(2020)
B = 100 #repeticiones Bootstrap 
df=data.frame(med)
remuestreo <- with(df,matrix(sample(med,size = 10,replace = TRUE), B, 10))
dim(remuestreo)
####### las medias de las submuestras
medias <- apply(remuestreo, 1, mean)
pruebat <- t.test(medias,alternative = "t",mu = 955,var.equal = F, conf.level = 0.90);
pruebat 
```

Conclusión: Los resultados consideran que la media no es 955 sino que está dentro en el rango 959.3-960.5

c) ¿Cuánto debería ser n en la expresión de la prueba t para que el error estándar Bootstrap sea el mismo que el asumido en la prueba?

Si los datos son mediciones, la primera prueba no tendría sentido porque solo es una media. En este caso la primera prueba estaría asumiendo que cada medición es una valor promedio diferente y no una medición. Para que el error estándar Bootstrap tenga sentido deberíamos tener más repeticiones y valores promedios de diferentes conjuntos de datos.

# Prueba t - Dos muestras independientes

Se midió un ángulo en seis series en una condición atmosférica particular utilizando un instrumento especializado, pero usando dos operarios simultáneamente. Los datos de las medidas angulares fueron:


```{r echo=FALSE}
table=data.frame(M1=character(),M2=character(),M3=character(),M4=character(),M5=character(),M6=character(),M7=character(),M8=character(),stringsAsFactors=FALSE)
table[1,]=0;table[2,]=0;
table$M1[1]="Operario X";table$M2[1]="112°47’34’’";table$M3[1]="112°44’39’’";table$M4[1]="113°01’34’’";table$M5[1]="112°57’30’’";table$M6[1]="113°00’14’’";table$M7[1]="111°59’58’’";table$M8[1]="112°09’58’’"

table$M1[2]="Operario Y";table$M2[2]="113°47’24’’";table$M3[2]="112°14’39’’";table$M4[2]="112°01’34’’";table$M5[2]="112°17’32’’";table$M6[2]="113°10’04’’";table$M7[2]="112°19’18’";table$M8[2]="112°59’48’";

kable(table, col.names = NULL) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

a) Determinar al 95% de nivel de confianza si las dos medias obtenidas por los operarios son estadísticamente iguales. Utilice la información del artículo mostrado en clase para decidir si las varianzas pueden considerarse iguales o no.

```{r}
#Crear el dataframe con la información de operarios
set.seed(2020);options(digits = 9)
opx<-c(112.7927778,	112.7441667,	113.0261111,	112.9583333,	113.0038889,	111.9994444,	112.1661111) 
opy<-c(113.79,112.2441667,112.0261111,112.2922222,113.1677778,112.3216667,112.9966667)
data=c(opx,opy)
operario <- gl(2, 7, 14, labels = c("operariox", "operarioy"))
df_oper <- data.frame(data,operario)
```

Definición de la hipótesis nula:

\[h_o: \bar{x}_{operario} = \bar{y}_{operario}\]

```{r}
####### estadisticas descriptivas por grupo
grupos <- group_by(df_oper, operario)
summarise(grupos, media = mean(data, na.rm = T), desv = sd(data,na.rm=T),cv = desv*100/media, muestra = length(data))
```

1. Seleccionar datos por operario y generar valores repetidos de cada operario 

```{r}
<<<<<<< HEAD
#Crear Datos por  operario
dataX <- c(filter(df_oper, operario == "operariox"));
dataY <- c(filter(df_oper, operario == "operarioy"));

n.datos <- with(df_oper, summary(operario)) #cada tamano de muestra
B = 1000 #repeticiones Bootstrap 
#las submuestras de cada metodo
met.x <- with(df_oper,matrix(sample(opx,size = n.datos[1]*B,replace = TRUE), B, n.datos[1]))
met.y <- with(df_oper,matrix(sample(opy,size = n.datos[2]*B,replace = TRUE), B, n.datos[2]))
dim(met.x)
dim(met.y)
```

2. Estimar las medias de las submuestras y calcular el vector de diferencia de medias

```{r}
####### las medias de las submuestras
medias.x <- apply(met.x, 1, mean)
medias.y <- apply(met.y, 1, mean)
######## el vector de diferencia de medias
stat.boot <- medias.x - medias.y 
length(stat.boot)
```

3. Gráfica de la distribución de diferencia de medias

```{r}
ggplot(data.frame(x = stat.boot), aes(x = x)) + geom_density()+
  labs(x = "diferencia de medias")+labs(y = "densidad")+
  labs(title = "Distribución de la diferencia de medias",
       subtitle = "Comparación de los dos operarios")+
  labs(caption = "(datos suministrados en clase)")+
  geom_vline(xintercept =0,col="azure4")

```

4. Cálculo del error estandar bootstrap y del error estandar convencional

```{r}
eebdm <- sd(stat.boot); eebdm   # error bootstrap
pruebat <- t.test(medias.x,medias.y, alternative = "two.sided",  mu=0, conf.level = 0.95);
eec <- c((mean(medias.x)-mean(medias.y))/pruebat$statistic);eec
```

5. Comparar ambos errores

```{r}
veces <- eebdm/eec;veces

# Cálculo del estadastico t bootstrap
tboot <- abs((mean(medias.x)-mean(medias.y))/eebdm)
# Obtener el p-valor del estadístico
pvalor_boot <- pt(tboot,n.datos[1]+n.datos[2]-2,lower.tail = F)
pvalor_boot
pvalor_usual <- pruebat$p.value
pvalor_usual
```

6. Graficar y aplicar la correción de Bonferroni

```{r}
curve(dt(x, 46), from = -5, to = 5, col = "orange",xlab = "cuantil t", ylab = "densidad", lwd = 2)
legend("topleft", legend = paste0("DF = ", 46),col = "sky blue",lty = 1, lwd = 2)
tt0025 <- qt(0.025,46,lower.tail = FALSE)
tt0975 <- qt(0.025,46,lower.tail = TRUE)
abline(h = 0, col = "darkgoldenrod2")
segments(tt0025, 0, tt0025, dt(tt0025,df = 46))
segments(-tt0025, 0, -tt0025, dt(tt0025,df = 46))
qbonf <- qt(pajust(2, 0.05)/2, 46, lower.tail = F)
segments(qbonf, 0, qbonf, dt(qbonf, df = 46), col = "darkblue")
segments(-qbonf, 0, -qbonf, dt(qbonf, df = 46), col = "darkblue")

```

# Prueba t-Dos muestras dependientes

Suponga del problema anterior que se seleccionó como mejor operario aquel que generó el menor coeficiente de variación de las mediciones angulares y se utilizó en el siguiente estudio. Ahora se generaron las mismas 6 medidas, pero una a las 10 de la mañana y otra a las 12 del mediodía, cuando la temperatura se había incrementado 5° C. Los datos se muestran a continuación:

```{r}

```


 







# Prueba T$^2$ Una muestra. 
```{r}
## Pregunta 6
distancia=c(100.02,200.12,300.08,399.96,419.94,519.99,620.04,720.08,100.06,199.45,298.08,398.96,420.15,520.02,621.01,721.11)
angulo=c(90.004444444, 90.002222222, 89.996666667, 90.017222222, 89.996666667, 90.005555556, 89.993333333, 90.001666667, 90.035833333, 90.021111111, 90.988333333, 89.017222222, 89.835555556, 89.038888889, 89.165555556, 89.029444444)
disp <- gl(2, 8, 16, labels = c("A", "B"))
datos5=data.frame(distancia,angulo,disp)
datos5a=datos5[1:8,]
datos5b=datos5[9:16,]
```


Se est?n probando dos dispositivos que permiten medir el ?ngulo recto y la distancia a una serie de puntos en un transecto. La figura muestra la situaci?n:

a. Realice la prueba t-Student de forma convencional para dos muestras independientes y saque las conclusiones por separado de la comparaci?n de las medias de longitud y ?ngulos para ambos dispositivos (sea cuidadoso al momento de obtener varianzas en ?ngulos). Utilice un nivel de confianza del 95% en cada caso.

```{r}
pda1=t.test(datos5a$distancia,datos5b$distancia, alternative = "two.sided", var.equal = T, mu=0, conf.level = 0.95) ## Se rechaza Ho
pda2=t.test(datos5a$angulo,datos5b$angulo, alternative = "two.sided", var.equal = T, mu=0, conf.level = 0.95) ## Se rechaza Ho

```

b. Compare los resultados anteriores con el resultado actualizado si utilizara la correcci?n de Bonferroni.

```{r}
pajust <- function(hipotesis,alfa){
  pvalor = 1-((1-alfa)^(1/hipotesis))
  return(pvalor)
}
crrb=pajust(2, 0.05) ## Calculo del nuevo nivel de significancia por Bonferroni
crrb=1-crrb ## Nivel de Confianza con Bonferroni

pdb1=t.test(datos5a$distancia,datos5b$distancia, alternative = "two.sided", var.equal = T, mu=0, conf.level = crrb) ## Se rechaza Ho
pdb2=t.test(datos5a$angulo,datos5b$angulo, alternative = "two.sided", var.equal = T, mu=0, conf.level = crrb) ## Se rechaza Ho
```

c. Obtenga el coeficiente de correlaci?n para este tipo de datos (Pearson) sin discriminar por dispositivo.

```{r}
cor(datos5$distancia,datos5$angulo)
```

d. Estime el error est?ndar para la diferencia de medias  por m?todo Bootstrap para ajustar la prueba t con este error y compare con el resultado sin el m?todo Bootstrap.

```{r}
n.datos <- with(datos5, summary(disp)) #cada tamano de muestra
B = 1000 #repeticiones Bootstrap 
#las submuestras de cada metodo
met.a.dist <- with(datos5a,
              matrix(sample(datos5a$distancia,
                            size = n.datos[1]*B,
                            replace = TRUE), B, n.datos[1]))
met.a.ang <- with(datos5a,
                   matrix(sample(datos5a$angulo,
                                 size = n.datos[1]*B,
                                 replace = TRUE), B, n.datos[1]))
met.b.dist <- with(datos5b,
              matrix(sample(datos5b$distancia,
                            size = n.datos[1]*B,
                            replace = TRUE), B, n.datos[2]))
met.b.ang <- with(datos5b,
                  matrix(sample(datos5b$angulo,
                                size = n.datos[1]*B,
                                replace = TRUE), B, n.datos[2]))

medias.a.dist<- apply(met.a.dist, 1, mean)
medias.a.ang<- apply(met.a.ang, 1, mean)
medias.b.dist <- apply(met.b.dist, 1, mean)
medias.b.ang<- apply(met.b.ang, 1, mean)

pdistd<-t.test(medias.a.dist,medias.b.dist,alternative = "two.sided",0, conf.level = 0.95, var.equal = F) ## Se rechaza Ho
pdang<-t.test(medias.a.ang,medias.b.ang,alternative = "two.sided", mu=0, conf.level = 0.95)  ## No se puede rechazar Ho -- mientras que en el est?ndar si se rechazo
pdang$p.value

eebdm <- sd(medias.a.dist-medias.b.dist) 
eecdist <- c((mean(medias.a.dist)-mean(medias.b.dist))/pdistd$statistic);eecdist
eebdma <- sd(medias.a.ang-medias.b.ang) 
eecang <- c((mean(medias.a.ang)-mean(medias.b.ang))/pdang$statistic);eecang
########## calculando el estadastico t bootstrap
tbootdist <- abs((mean(medias.a.dist)-mean(medias.b.dist))/eebdm)
pvalor_bootdist <- pt(tboot,n.datos[1]+n.datos[2]-2,lower.tail = F)
tbootang <- abs((mean(medias.a.ang)-mean(medias.b.ang))/eebdma)
pvalor_bootangt <- pt(tbootang,n.datos[1]+n.datos[2]-2,lower.tail = F)

```

e. Use el resultado anterior y ajuste adem?s con la correcci?n de Bonferroni.

```{r}

## E


## Con Bonferroni a una confianza de 97.5% a cada uno por separado, no se puede rechazar la Ho de distancia igual que el ?ngulo
```


f. Aplique la prueba T2 de Hotelling para comparar el vector de medias bivariado asumiendo varianzas iguales y un nivel de confianza del 95%.
	
	
Ho:[???(??_(d-A)@??_(a-A) )]=[???(??_(d-B)@??_(a-B) )]

```{r}
Z=as.matrix(datos5[,1:2])
g=as.matrix(datos5[,3])

PruebaH2 <- HotellingsT2(Z~g, mu = c(0,0)) ##
```


g. Utilice la prueba M de Box de Biotools y verifique si ambas matrices de varianzas y covarianzas son estad?sticamente iguales al 95%. (cuide el c?lculo de las varianzas en datos angulares). De ser diferentes las varianzas consulte el texto de Wichern para que utilice la prueba de Hotelling para varianzas y covarianzas desiguales y con la ayuda de alguna funci?n en R/Python contraste las hip?tesis bivariadas de longitud y ?ngulo nuevamente.

```{r}
## g

library(biotools)
## Matriz de varianzas y covarianzas metodo A
data.a <- as.matrix((filter(datos5[, 1:2], disp == "A")), ncol = 2)
sa <- var(data.a)
## Matriz de varianzas y covarianzas metodo B
data.b <- as.matrix((filter(datos5[, 1:2], disp == "B")), ncol = 2)
sb <- var(data.b)
## Prueba M de Box
boxM(dft2i[,-3],dft2i[,3])

require(ergm)

approx.hotelling.diff.test(datos5a[,-3], datos5b[,-3], mu0 = 0, assume.indep = T, var.equal = T)

require(rrcov)

T2.test(datos5a[,-3],
        datos5b[,-3], method = "c")
```


h. Realice alg?n gr?fico radial o de datos circulares para visualizar el comportamiento de los ?ngulos y simult?neamente visualice las distancias.

```{r}
# h

ggplot(df, aes(x=distancia, y=angulo, col=dispositivo, group=dispositivo)) + geom_point() + coord_polar()

```

i. Si ambos dispositivos se comportan igual para ambas medidas (es decir no se rechaz? Ho bivariada, utilice el an?lisis de regresi?n lineal para ajustar un modelo para estimar la distancia a partir del ?ngulo. ?Vale la pena este ajuste? Ajuste el mismo modelo con el inverso de la distancia y compare resultados. ?Como a mayor distancia la medida de longitud se puede tornar m?s imprecisa, valdr?a ponderar el ?ngulo por el inverso de la distancia para obtener el ?ngulo promedio de todas las medidas? Realice el c?lculo ponderado y compare con la media aritm?tica usual del ?ngulo. Explique estos resultados.

```{r}
# i

model1=lm(datos5$distancia ~ datos5$angulo)
summary(model1) 

model2=lm(1/datos5$distancia ~ datos5$angulo)
summary(model2)

datos5a$inversdis=1/datos5a$distancia
datos5a$angulopond=datos5a$inversdis*datos5a$angulo
datos5b$inversdis=1/datos5b$distancia
datos5b$angulopond=datos5b$inversdis*datos5b$angulo
cor(datos5b$angulopond,datos5a$angulopond)
mean(datos5a$angulopond)
mean(datos5a$angulopond)
```





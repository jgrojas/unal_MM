---
title: "Pruebas de hipótesis en R"
author: "JRojas, MRamirez, LRomero,ADarghan"
date: "6/24/2020"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '1'
    toc_float: yes
  bookdown::html_document2:
    number_sections: no
    toc: yes
    toc_depth: 1
    toc_float: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

A continuación se presentan una serie de ejercicios que permitiran interiorizar los conocimientos aprendidos en relación a pruebas de hipótesis desde R. El documento contiene la solución de 6 ejercicios que hacen énfasis en:

* Prueba t - Una muestra
* Prueba t - Dos muestras independientes
* Prueba t - Dos muestras dependientes
* Función distribución uniforme
* Prueba F para el cociente de dos varianzas
* Prueba T$^2$ de Hotelling para dos muestras independientes

El desarrollo del taller hace parte del contenido académico elaborado por el profesor Aquiles Enrique Darghan Contreras para la materia de de Métodos Multivariados.

Previo a la solución de los ejercicios es necesario instalar y cargar las siguientes librerías y funciones diseñadas para el análisis.

```{r message=FALSE, include=TRUE}
library(dplyr)
library(kableExtra)
library(ggplot2)
```

```{r message=FALSE}
pajust <- function(hipotesis,alfa){
  pvalor = 1-((1-alfa)^(1/hipotesis))
  return(pvalor)
}
```

# Prueba t-Una muestra.  

Una línea base de longitud calibrada en 955m se midió 10 veces. Cada medida es independiente y se hizo con la misma precisión.

Los datos de las mediciones son:
```{r echo=FALSE}

med=c(965.1,955.1,954.8,956.2,956.4,957.2,958.1,960.4,953.2,954.8)
table=data.frame(M1=numeric(),M2=numeric(),M3=numeric(),M4=numeric(),M5=numeric(),M6=numeric(),M7=numeric(),M8=numeric(),M9=numeric(),M10=numeric())
table[1,]=0
table$M1[0]=med[1];table$M2=med[2];table$M3=med[3];table$M4=med[4];table$M5=med[5];table$M6=med[6];table$M7=med[7];table$M8=med[8];table$M9=med[9];table$M10=med[10]

kable(table) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

a) Pruebe utilizando un nivel de confianza del 10% si la distancia medida es estadísticamente diferente de la calibrada.

```{r}
med=c(965.1,955.1,954.8,956.2,956.4,957.2,958.1,960.4,953.2,954.8)
pruebat <- t.test(med,alternative = "t",mu = 0,var.equal = F, conf.level = 0.90);
pruebat #La media  está en la cola inferior
```

b) Remuestree el vector de mediciones y obtenga el error estándar Bootstrap y utilícelo en la prueba t-Student y compare con el resultado anterior( Explique). (Realice 100 simulaciones)

```{r}
set.seed(2020)
B = 100 #repeticiones Bootstrap 
df=data.frame(med)
remuestreo <- with(df,matrix(sample(med,size = 10,replace = TRUE), B, 10))
dim(remuestreo)
####### las medias de las submuestras
medias <- apply(remuestreo, 1, mean)
pruebat <- t.test(medias,alternative = "t",mu = 955,var.equal = F, conf.level = 0.90);
pruebat 
```

Conclusión: Los resultados consideran que la media no es 955 sino que está dentro en el rango 959.3-960.5

c) ¿Cuánto debería ser n en la expresión de la prueba t para que el error estándar Bootstrap sea el mismo que el asumido en la prueba?

Si los datos son mediciones, la primera prueba no tendría sentido porque solo es una media. En este caso la primera prueba estaría asumiendo que cada medición es una valor promedio diferente y no una medición. Para que el error estándar Bootstrap tenga sentido deberíamos tener más repeticiones y valores promedios de diferentes conjuntos de datos.

# Prueba t - Dos muestras independientes

Se midió un ángulo en seis series en una condición atmosférica particular utilizando un instrumento especializado, pero usando dos operarios simultáneamente. Los datos de las medidas angulares fueron:


```{r echo=FALSE}
table=data.frame(M1=character(),M2=character(),M3=character(),M4=character(),M5=character(),M6=character(),M7=character(),M8=character(),stringsAsFactors=FALSE)
table[1,]=0;table[2,]=0;
table$M1[1]="Operario X";table$M2[1]="112°47’34’’";table$M3[1]="112°44’39’’";table$M4[1]="113°01’34’’";table$M5[1]="112°57’30’’";table$M6[1]="113°00’14’’";table$M7[1]="111°59’58’’";table$M8[1]="112°09’58’’"

table$M1[2]="Operario Y";table$M2[2]="113°47’24’’";table$M3[2]="112°14’39’’";table$M4[2]="112°01’34’’";table$M5[2]="112°17’32’’";table$M6[2]="113°10’04’’";table$M7[2]="112°19’18’";table$M8[2]="112°59’48’";

kable(table, col.names = NULL) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```

a) Determinar al 95% de nivel de confianza si las dos medias obtenidas por los operarios son estadísticamente iguales. Utilice la información del artículo mostrado en clase para decidir si las varianzas pueden considerarse iguales o no.


```{r}
#Crear el dataframe con la información de operarios
set.seed(2020);options(digits = 9)
opx<-c(112.7927778,	112.7441667,	113.0261111,	112.9583333,	113.0038889,	111.9994444,	112.1661111) 
opy<-c(113.79,112.2441667,112.0261111,112.2922222,113.1677778,112.3216667,112.9966667)
data=c(opx,opy)
operario <- gl(2, 7, 14, labels = c("operariox", "operarioy"))
df_oper <- data.frame(data,operario)
```

Definición de la hipótesis nula:

\[h_o: \bar{x}_{operario} = \bar{y}_{operario}\]

```{r}
####### estadisticas descriptivas por grupo
grupos <- group_by(df_oper, operario)
summarise(grupos, media = mean(data, na.rm = T), desv = sd(data,na.rm=T),cv = desv*100/media, muestra = length(data))
```

1. Seleccionar datos por operario y generar valores repetidos de cada operario 

```{r}
#Crear Datos por  operario
dataX <- c(filter(df_oper, operario == "operariox"));
dataY <- c(filter(df_oper, operario == "operarioy"));

n.datos <- with(df_oper, summary(operario)) #cada tamano de muestra
B = 1000 #repeticiones Bootstrap 
#las submuestras de cada metodo
met.x <- with(df_oper,matrix(sample(opx,size = n.datos[1]*B,replace = TRUE), B, n.datos[1]))
met.y <- with(df_oper,matrix(sample(opy,size = n.datos[2]*B,replace = TRUE), B, n.datos[2]))
dim(met.x)
dim(met.y)
```

2. Estimar las medias de las submuestras y calcular el vector de diferencia de medias

```{r}
####### las medias de las submuestras
medias.x <- apply(met.x, 1, mean)
medias.y <- apply(met.y, 1, mean)
######## el vector de diferencia de medias
stat.boot <- medias.x - medias.y 
length(stat.boot)
```

3. Gráfica de la distribución de diferencia de medias

```{r}
ggplot(data.frame(x = stat.boot), aes(x = x)) + geom_density()+
  labs(x = "diferencia de medias")+labs(y = "densidad")+
  labs(title = "Distribución de la diferencia de medias",
       subtitle = "Comparación de los dos operarios")+
  labs(caption = "(datos suministrados en clase)")+
  geom_vline(xintercept =0,col="azure4")

```

4. Cálculo del error estandar bootstrap y del error estandar convencional

```{r}
eebdm <- sd(stat.boot); eebdm   # error bootstrap
pruebat <- t.test(medias.x,medias.y, alternative = "two.sided",  mu=0, conf.level = 0.95);
eec <- c((mean(medias.x)-mean(medias.y))/pruebat$statistic);eec
```

5. Comparar ambos errores

```{r}
veces <- eebdm/eec;veces

# Cálculo del estadastico t bootstrap
tboot <- abs((mean(medias.x)-mean(medias.y))/eebdm)
# Obtener el p-valor del estadístico
pvalor_boot <- pt(tboot,n.datos[1]+n.datos[2]-2,lower.tail = F)
pvalor_boot
pvalor_usual <- pruebat$p.value
pvalor_usual
```

6. Graficar y aplicar la correción de Bonferroni

```{r}
curve(dt(x, 46), from = -5, to = 5, col = "orange",xlab = "cuantil t", ylab = "densidad", lwd = 2)
legend("topleft", legend = paste0("DF = ", 46),col = "sky blue",lty = 1, lwd = 2)
tt0025 <- qt(0.025,46,lower.tail = FALSE)
tt0975 <- qt(0.025,46,lower.tail = TRUE)
abline(h = 0, col = "darkgoldenrod2")
segments(tt0025, 0, tt0025, dt(tt0025,df = 46))
segments(-tt0025, 0, -tt0025, dt(tt0025,df = 46))
qbonf <- qt(pajust(2, 0.05)/2, 46, lower.tail = F)
segments(qbonf, 0, qbonf, dt(qbonf, df = 46), col = "darkblue")
segments(-qbonf, 0, -qbonf, dt(qbonf, df = 46), col = "darkblue")

```



```{r}

```
